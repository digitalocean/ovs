Description: Revert "dpif-netlink: don't allocate per thread netlink sockets"
This reverts:
 69c51582ff786a68fc325c1c50624715482bc460
 769b50349f28c5f9e4bff102bc61dadcb9b99c37
 790a437229744270bebf7e707e298910e102254f
 d240e46acac3a63c6bdd0ade159d7a556259f855
to resolve SYS-1615 (OVS thundering herd).
Author: Nishanth Aravamudan <naravamudan@digitalocean.com>

---
Origin: upstream, see hashes above
Forwarded: no
Last-Update: 2020-03-11

--- openvswitch-2.11.2.orig/lib/dpif-netlink.c
+++ openvswitch-2.11.2/lib/dpif-netlink.c
@@ -78,10 +78,6 @@ enum { MAX_PORTS = USHRT_MAX };
 #define FLOW_DUMP_MAX_BATCH 50
 #define OPERATE_MAX_OPS 50
 
-#ifndef EPOLLEXCLUSIVE
-#define EPOLLEXCLUSIVE (1u << 28)
-#endif
-
 struct dpif_netlink_dp {
     /* Generic Netlink header. */
     uint8_t cmd;
@@ -174,6 +170,7 @@ struct dpif_windows_vport_sock {
 #endif
 
 struct dpif_handler {
+    struct dpif_channel *channels;/* Array of channels for each handler. */
     struct epoll_event *epoll_events;
     int epoll_fd;                 /* epoll fd that includes channel socks. */
     int n_events;                 /* Num events returned by epoll_wait(). */
@@ -196,7 +193,6 @@ struct dpif_netlink {
     struct fat_rwlock upcall_lock;
     struct dpif_handler *handlers;
     uint32_t n_handlers;           /* Num of upcall handlers. */
-    struct dpif_channel *channels; /* Array of channels for each port. */
     int uc_array_size;             /* Size of 'handler->channels' and */
                                    /* 'handler->epoll_events'. */
 
@@ -234,7 +230,7 @@ static bool ovs_tunnels_out_of_tree = tr
 static int dpif_netlink_init(void);
 static int open_dpif(const struct dpif_netlink_dp *, struct dpif **);
 static uint32_t dpif_netlink_port_get_pid(const struct dpif *,
-                                          odp_port_t port_no);
+                                          odp_port_t port_no, uint32_t hash);
 static void dpif_netlink_handler_uninit(struct dpif_handler *handler);
 static int dpif_netlink_refresh_channels(struct dpif_netlink *,
                                          uint32_t n_handlers);
@@ -246,42 +242,6 @@ static int dpif_netlink_port_query__(con
                                      odp_port_t port_no, const char *port_name,
                                      struct dpif_port *dpif_port);
 
-static int
-create_nl_sock(struct dpif_netlink *dpif OVS_UNUSED, struct nl_sock **socksp)
-    OVS_REQ_WRLOCK(dpif->upcall_lock)
-{
-#ifndef _WIN32
-    return nl_sock_create(NETLINK_GENERIC, socksp);
-#else
-    /* Pick netlink sockets to use in a round-robin fashion from each
-     * handler's pool of sockets. */
-    struct dpif_handler *handler = &dpif->handlers[0];
-    struct dpif_windows_vport_sock *sock_pool = handler->vport_sock_pool;
-    size_t index = handler->last_used_pool_idx;
-
-    /* A pool of sockets is allocated when the handler is initialized. */
-    if (sock_pool == NULL) {
-        *socksp = NULL;
-        return EINVAL;
-    }
-
-    ovs_assert(index < VPORT_SOCK_POOL_SIZE);
-    *socksp = sock_pool[index].nl_sock;
-    ovs_assert(*socksp);
-    index = (index == VPORT_SOCK_POOL_SIZE - 1) ? 0 : index + 1;
-    handler->last_used_pool_idx = index;
-    return 0;
-#endif
-}
-
-static void
-close_nl_sock(struct nl_sock *socksp)
-{
-#ifndef _WIN32
-    nl_sock_destroy(socksp);
-#endif
-}
-
 static struct dpif_netlink *
 dpif_netlink_cast(const struct dpif *dpif)
 {
@@ -371,6 +331,43 @@ open_dpif(const struct dpif_netlink_dp *
     return 0;
 }
 
+/* Destroys the netlink sockets pointed by the elements in 'socksp'
+ * and frees the 'socksp'.  */
+static void
+vport_del_socksp__(struct nl_sock **socksp, uint32_t n_socks)
+{
+    size_t i;
+
+    for (i = 0; i < n_socks; i++) {
+        nl_sock_destroy(socksp[i]);
+    }
+
+    free(socksp);
+}
+
+/* Creates an array of netlink sockets.  Returns an array of the
+ * corresponding pointers.  Records the error in 'error'. */
+static struct nl_sock **
+vport_create_socksp__(uint32_t n_socks, int *error)
+{
+    struct nl_sock **socksp = xzalloc(n_socks * sizeof *socksp);
+    size_t i;
+
+    for (i = 0; i < n_socks; i++) {
+        *error = nl_sock_create(NETLINK_GENERIC, &socksp[i]);
+        if (*error) {
+            goto error;
+        }
+    }
+
+    return socksp;
+
+error:
+    vport_del_socksp__(socksp, n_socks);
+
+    return NULL;
+}
+
 #ifdef _WIN32
 static void
 vport_delete_sock_pool(struct dpif_handler *handler)
@@ -425,34 +422,129 @@ error:
     vport_delete_sock_pool(handler);
     return error;
 }
+
+/* Returns an array pointers to netlink sockets.  The sockets are picked from a
+ * pool. Records the error in 'error'. */
+static struct nl_sock **
+vport_create_socksp_windows(struct dpif_netlink *dpif, int *error)
+    OVS_REQ_WRLOCK(dpif->upcall_lock)
+{
+    uint32_t n_socks = dpif->n_handlers;
+    struct nl_sock **socksp;
+    size_t i;
+
+    ovs_assert(n_socks <= 1);
+    socksp = xzalloc(n_socks * sizeof *socksp);
+
+    /* Pick netlink sockets to use in a round-robin fashion from each
+     * handler's pool of sockets. */
+    for (i = 0; i < n_socks; i++) {
+        struct dpif_handler *handler = &dpif->handlers[i];
+        struct dpif_windows_vport_sock *sock_pool = handler->vport_sock_pool;
+        size_t index = handler->last_used_pool_idx;
+
+        /* A pool of sockets is allocated when the handler is initialized. */
+        if (sock_pool == NULL) {
+            free(socksp);
+            *error = EINVAL;
+            return NULL;
+        }
+
+        ovs_assert(index < VPORT_SOCK_POOL_SIZE);
+        socksp[i] = sock_pool[index].nl_sock;
+        socksp[i] = sock_pool[index].nl_sock;
+        ovs_assert(socksp[i]);
+        index = (index == VPORT_SOCK_POOL_SIZE - 1) ? 0 : index + 1;
+        handler->last_used_pool_idx = index;
+    }
+
+    return socksp;
+}
+
+static void
+vport_del_socksp_windows(struct dpif_netlink *dpif, struct nl_sock **socksp)
+{
+    free(socksp);
+}
 #endif /* _WIN32 */
 
-/* Given the port number 'port_idx', extracts the pid of netlink socket
- * associated to the port and assigns it to 'upcall_pid'. */
+static struct nl_sock **
+vport_create_socksp(struct dpif_netlink *dpif, int *error)
+{
+#ifdef _WIN32
+    return vport_create_socksp_windows(dpif, error);
+#else
+    return vport_create_socksp__(dpif->n_handlers, error);
+#endif
+}
+
+static void
+vport_del_socksp(struct dpif_netlink *dpif, struct nl_sock **socksp)
+{
+#ifdef _WIN32
+    vport_del_socksp_windows(dpif, socksp);
+#else
+    vport_del_socksp__(socksp, dpif->n_handlers);
+#endif
+}
+
+/* Given the array of pointers to netlink sockets 'socksp', returns
+ * the array of corresponding pids. If the 'socksp' is NULL, returns
+ * a single-element array of value 0. */
+static uint32_t *
+vport_socksp_to_pids(struct nl_sock **socksp, uint32_t n_socks)
+{
+    uint32_t *pids;
+
+    if (!socksp) {
+        pids = xzalloc(sizeof *pids);
+    } else {
+        size_t i;
+
+        pids = xzalloc(n_socks * sizeof *pids);
+        for (i = 0; i < n_socks; i++) {
+            pids[i] = nl_sock_pid(socksp[i]);
+        }
+    }
+
+    return pids;
+}
+
+/* Given the port number 'port_idx', extracts the pids of netlink sockets
+ * associated to the port and assigns it to 'upcall_pids'. */
 static bool
-vport_get_pid(struct dpif_netlink *dpif, uint32_t port_idx,
-              uint32_t *upcall_pid)
+vport_get_pids(struct dpif_netlink *dpif, uint32_t port_idx,
+               uint32_t **upcall_pids)
 {
+    uint32_t *pids;
+    size_t i;
+
     /* Since the nl_sock can only be assigned in either all
-     * or none "dpif" channels, the following check
+     * or none "dpif->handlers" channels, the following check
      * would suffice. */
-    if (!dpif->channels[port_idx].sock) {
+    if (!dpif->handlers[0].channels[port_idx].sock) {
         return false;
     }
     ovs_assert(!WINDOWS || dpif->n_handlers <= 1);
 
-    *upcall_pid = nl_sock_pid(dpif->channels[port_idx].sock);
+    pids = xzalloc(dpif->n_handlers * sizeof *pids);
+
+    for (i = 0; i < dpif->n_handlers; i++) {
+        pids[i] = nl_sock_pid(dpif->handlers[i].channels[port_idx].sock);
+    }
+
+    *upcall_pids = pids;
 
     return true;
 }
 
 static int
-vport_add_channel(struct dpif_netlink *dpif, odp_port_t port_no,
-                  struct nl_sock *socksp)
+vport_add_channels(struct dpif_netlink *dpif, odp_port_t port_no,
+                   struct nl_sock **socksp)
 {
     struct epoll_event event;
     uint32_t port_idx = odp_to_u32(port_no);
-    size_t i;
+    size_t i, j;
     int error;
 
     if (dpif->handlers == NULL) {
@@ -461,7 +553,7 @@ vport_add_channel(struct dpif_netlink *d
 
     /* We assume that the datapath densely chooses port numbers, which can
      * therefore be used as an index into 'channels' and 'epoll_events' of
-     * 'dpif'. */
+     * 'dpif->handler'. */
     if (port_idx >= dpif->uc_array_size) {
         uint32_t new_size = port_idx + 1;
 
@@ -471,16 +563,16 @@ vport_add_channel(struct dpif_netlink *d
             return EFBIG;
         }
 
-        dpif->channels = xrealloc(dpif->channels,
-                                  new_size * sizeof *dpif->channels);
-
-        for (i = dpif->uc_array_size; i < new_size; i++) {
-            dpif->channels[i].sock = NULL;
-        }
-
         for (i = 0; i < dpif->n_handlers; i++) {
             struct dpif_handler *handler = &dpif->handlers[i];
 
+            handler->channels = xrealloc(handler->channels,
+                                         new_size * sizeof *handler->channels);
+
+            for (j = dpif->uc_array_size; j < new_size; j++) {
+                handler->channels[j].sock = NULL;
+            }
+
             handler->epoll_events = xrealloc(handler->epoll_events,
                 new_size * sizeof *handler->epoll_events);
 
@@ -489,33 +581,33 @@ vport_add_channel(struct dpif_netlink *d
     }
 
     memset(&event, 0, sizeof event);
-    event.events = EPOLLIN | EPOLLEXCLUSIVE;
+    event.events = EPOLLIN;
     event.data.u32 = port_idx;
 
     for (i = 0; i < dpif->n_handlers; i++) {
         struct dpif_handler *handler = &dpif->handlers[i];
 
 #ifndef _WIN32
-        if (epoll_ctl(handler->epoll_fd, EPOLL_CTL_ADD, nl_sock_fd(socksp),
+        if (epoll_ctl(handler->epoll_fd, EPOLL_CTL_ADD, nl_sock_fd(socksp[i]),
                       &event) < 0) {
             error = errno;
             goto error;
         }
 #endif
+        dpif->handlers[i].channels[port_idx].sock = socksp[i];
+        dpif->handlers[i].channels[port_idx].last_poll = LLONG_MIN;
     }
-    dpif->channels[port_idx].sock = socksp;
-    dpif->channels[port_idx].last_poll = LLONG_MIN;
 
     return 0;
 
 error:
+    for (j = 0; j < i; j++) {
 #ifndef _WIN32
-    while (i--) {
-        epoll_ctl(dpif->handlers[i].epoll_fd, EPOLL_CTL_DEL,
-                  nl_sock_fd(socksp), NULL);
-    }
+        epoll_ctl(dpif->handlers[j].epoll_fd, EPOLL_CTL_DEL,
+                  nl_sock_fd(socksp[j]), NULL);
 #endif
-    dpif->channels[port_idx].sock = NULL;
+        dpif->handlers[j].channels[port_idx].sock = NULL;
+    }
 
     return error;
 }
@@ -526,8 +618,14 @@ vport_del_channels(struct dpif_netlink *
     uint32_t port_idx = odp_to_u32(port_no);
     size_t i;
 
-    if (!dpif->handlers || port_idx >= dpif->uc_array_size
-        || !dpif->channels[port_idx].sock) {
+    if (!dpif->handlers || port_idx >= dpif->uc_array_size) {
+        return;
+    }
+
+    /* Since the sock can only be assigned in either all or none
+     * of "dpif->handlers" channels, the following check would
+     * suffice. */
+    if (!dpif->handlers[0].channels[port_idx].sock) {
         return;
     }
 
@@ -535,14 +633,12 @@ vport_del_channels(struct dpif_netlink *
         struct dpif_handler *handler = &dpif->handlers[i];
 #ifndef _WIN32
         epoll_ctl(handler->epoll_fd, EPOLL_CTL_DEL,
-                  nl_sock_fd(dpif->channels[port_idx].sock), NULL);
+                  nl_sock_fd(handler->channels[port_idx].sock), NULL);
+        nl_sock_destroy(handler->channels[port_idx].sock);
 #endif
+        handler->channels[port_idx].sock = NULL;
         handler->event_offset = handler->n_events = 0;
     }
-#ifndef _WIN32
-    nl_sock_destroy(dpif->channels[port_idx].sock);
-#endif
-    dpif->channels[port_idx].sock = NULL;
 }
 
 static void
@@ -559,7 +655,10 @@ destroy_all_channels(struct dpif_netlink
         struct dpif_netlink_vport vport_request;
         uint32_t upcall_pids = 0;
 
-        if (!dpif->channels[i].sock) {
+        /* Since the sock can only be assigned in either all or none
+         * of "dpif->handlers" channels, the following check would
+         * suffice. */
+        if (!dpif->handlers[0].channels[i].sock) {
             continue;
         }
 
@@ -580,11 +679,11 @@ destroy_all_channels(struct dpif_netlink
 
         dpif_netlink_handler_uninit(handler);
         free(handler->epoll_events);
+        free(handler->channels);
     }
-    free(dpif->channels);
+
     free(dpif->handlers);
     dpif->handlers = NULL;
-    dpif->channels = NULL;
     dpif->n_handlers = 0;
     dpif->uc_array_size = 0;
 }
@@ -747,13 +846,13 @@ dpif_netlink_port_add__(struct dpif_netl
 {
     struct dpif_netlink_vport request, reply;
     struct ofpbuf *buf;
-    struct nl_sock *socksp = NULL;
-    uint32_t upcall_pids = 0;
+    struct nl_sock **socksp = NULL;
+    uint32_t *upcall_pids;
     int error = 0;
 
     if (dpif->handlers) {
-        error = create_nl_sock(dpif, &socksp);
-        if (error) {
+        socksp = vport_create_socksp(dpif, &error);
+        if (!socksp) {
             return error;
         }
     }
@@ -765,11 +864,9 @@ dpif_netlink_port_add__(struct dpif_netl
     request.name = name;
 
     request.port_no = *port_nop;
-    if (socksp) {
-        upcall_pids = nl_sock_pid(socksp);
-    }
-    request.n_upcall_pids = 1;
-    request.upcall_pids = &upcall_pids;
+    upcall_pids = vport_socksp_to_pids(socksp, dpif->n_handlers);
+    request.n_upcall_pids = socksp ? dpif->n_handlers : 1;
+    request.upcall_pids = upcall_pids;
 
     if (options) {
         request.options = options->data;
@@ -785,27 +882,31 @@ dpif_netlink_port_add__(struct dpif_netl
                       dpif_name(&dpif->dpif), *port_nop);
         }
 
-        close_nl_sock(socksp);
+        vport_del_socksp(dpif, socksp);
         goto exit;
     }
 
-    error = vport_add_channel(dpif, *port_nop, socksp);
-    if (error) {
-        VLOG_INFO("%s: could not add channel for port %s",
-                    dpif_name(&dpif->dpif), name);
+    if (socksp) {
+        error = vport_add_channels(dpif, *port_nop, socksp);
+        if (error) {
+            VLOG_INFO("%s: could not add channel for port %s",
+                      dpif_name(&dpif->dpif), name);
 
-        /* Delete the port. */
-        dpif_netlink_vport_init(&request);
-        request.cmd = OVS_VPORT_CMD_DEL;
-        request.dp_ifindex = dpif->dp_ifindex;
-        request.port_no = *port_nop;
-        dpif_netlink_vport_transact(&request, NULL, NULL);
-        close_nl_sock(socksp);
-        goto exit;
+            /* Delete the port. */
+            dpif_netlink_vport_init(&request);
+            request.cmd = OVS_VPORT_CMD_DEL;
+            request.dp_ifindex = dpif->dp_ifindex;
+            request.port_no = *port_nop;
+            dpif_netlink_vport_transact(&request, NULL, NULL);
+            vport_del_socksp(dpif, socksp);
+            goto exit;
+        }
     }
+    free(socksp);
 
 exit:
     ofpbuf_delete(buf);
+    free(upcall_pids);
 
     return error;
 }
@@ -1030,7 +1131,7 @@ dpif_netlink_port_query_by_name(const st
 
 static uint32_t
 dpif_netlink_port_get_pid__(const struct dpif_netlink *dpif,
-                            odp_port_t port_no)
+                            odp_port_t port_no, uint32_t hash)
     OVS_REQ_RDLOCK(dpif->upcall_lock)
 {
     uint32_t port_idx = odp_to_u32(port_no);
@@ -1040,13 +1141,14 @@ dpif_netlink_port_get_pid__(const struct
         /* The ODPP_NONE "reserved" port number uses the "ovs-system"'s
          * channel, since it is not heavily loaded. */
         uint32_t idx = port_idx >= dpif->uc_array_size ? 0 : port_idx;
+        struct dpif_handler *h = &dpif->handlers[hash % dpif->n_handlers];
 
         /* Needs to check in case the socket pointer is changed in between
          * the holding of upcall_lock.  A known case happens when the main
          * thread deletes the vport while the handler thread is handling
          * the upcall from that port. */
-        if (dpif->channels[idx].sock) {
-            pid = nl_sock_pid(dpif->channels[idx].sock);
+        if (h->channels[idx].sock) {
+            pid = nl_sock_pid(h->channels[idx].sock);
         }
     }
 
@@ -1054,13 +1156,14 @@ dpif_netlink_port_get_pid__(const struct
 }
 
 static uint32_t
-dpif_netlink_port_get_pid(const struct dpif *dpif_, odp_port_t port_no)
+dpif_netlink_port_get_pid(const struct dpif *dpif_, odp_port_t port_no,
+                          uint32_t hash)
 {
     const struct dpif_netlink *dpif = dpif_netlink_cast(dpif_);
     uint32_t ret;
 
     fat_rwlock_rdlock(&dpif->upcall_lock);
-    ret = dpif_netlink_port_get_pid__(dpif, port_no);
+    ret = dpif_netlink_port_get_pid__(dpif, port_no, hash);
     fat_rwlock_unlock(&dpif->upcall_lock);
 
     return ret;
@@ -2305,41 +2408,42 @@ dpif_netlink_refresh_channels(struct dpi
     dpif_netlink_port_dump_start__(dpif, &dump);
     while (!dpif_netlink_port_dump_next__(dpif, &dump, &vport, &buf)) {
         uint32_t port_no = odp_to_u32(vport.port_no);
-        uint32_t upcall_pid;
+        uint32_t *upcall_pids = NULL;
         int error;
 
         if (port_no >= dpif->uc_array_size
-            || !vport_get_pid(dpif, port_no, &upcall_pid)) {
-            struct nl_sock *socksp;
-            error = create_nl_sock(dpif, &socksp);
+            || !vport_get_pids(dpif, port_no, &upcall_pids)) {
+            struct nl_sock **socksp = vport_create_socksp(dpif, &error);
 
-            if (error) {
+            if (!socksp) {
                 goto error;
             }
 
-            error = vport_add_channel(dpif, vport.port_no, socksp);
+            error = vport_add_channels(dpif, vport.port_no, socksp);
             if (error) {
                 VLOG_INFO("%s: could not add channels for port %s",
                           dpif_name(&dpif->dpif), vport.name);
-                nl_sock_destroy(socksp);
+                vport_del_socksp(dpif, socksp);
                 retval = error;
                 goto error;
             }
-            upcall_pid = nl_sock_pid(socksp);
+            upcall_pids = vport_socksp_to_pids(socksp, dpif->n_handlers);
+            free(socksp);
         }
 
         /* Configure the vport to deliver misses to 'sock'. */
         if (vport.upcall_pids[0] == 0
-            || vport.n_upcall_pids != 1
-            || upcall_pid != vport.upcall_pids[0]) {
+            || vport.n_upcall_pids != dpif->n_handlers
+            || memcmp(upcall_pids, vport.upcall_pids, n_handlers * sizeof
+                      *upcall_pids)) {
             struct dpif_netlink_vport vport_request;
 
             dpif_netlink_vport_init(&vport_request);
             vport_request.cmd = OVS_VPORT_CMD_SET;
             vport_request.dp_ifindex = dpif->dp_ifindex;
             vport_request.port_no = vport.port_no;
-            vport_request.n_upcall_pids = 1;
-            vport_request.upcall_pids = &upcall_pid;
+            vport_request.n_upcall_pids = dpif->n_handlers;
+            vport_request.upcall_pids = upcall_pids;
             error = dpif_netlink_vport_transact(&vport_request, NULL, NULL);
             if (error) {
                 VLOG_WARN_RL(&error_rl,
@@ -2360,9 +2464,11 @@ dpif_netlink_refresh_channels(struct dpi
         if (port_no < keep_channels_nbits) {
             bitmap_set1(keep_channels, port_no);
         }
+        free(upcall_pids);
         continue;
 
     error:
+        free(upcall_pids);
         vport_del_channels(dpif, vport.port_no);
     }
     nl_dump_done(&dump);
@@ -2621,7 +2727,7 @@ dpif_netlink_recv__(struct dpif_netlink
 
     while (handler->event_offset < handler->n_events) {
         int idx = handler->epoll_events[handler->event_offset].data.u32;
-        struct dpif_channel *ch = &dpif->channels[idx];
+        struct dpif_channel *ch = &dpif->handlers[handler_id].channels[idx];
 
         handler->event_offset++;
 
@@ -2723,14 +2829,16 @@ dpif_netlink_recv_purge__(struct dpif_ne
     OVS_REQ_WRLOCK(dpif->upcall_lock)
 {
     if (dpif->handlers) {
-        size_t i;
+        size_t i, j;
 
-        if (!dpif->channels[0].sock) {
-            return;
-        }
         for (i = 0; i < dpif->uc_array_size; i++ ) {
+            if (!dpif->handlers[0].channels[i].sock) {
+                continue;
+            }
 
-            nl_sock_drain(dpif->channels[i].sock);
+            for (j = 0; j < dpif->n_handlers; j++) {
+                nl_sock_drain(dpif->handlers[j].channels[i].sock);
+            }
         }
     }
 }
--- openvswitch-2.11.2.orig/lib/dpif-provider.h
+++ openvswitch-2.11.2/lib/dpif-provider.h
@@ -192,7 +192,16 @@ struct dpif_class {
 
     /* Returns the Netlink PID value to supply in OVS_ACTION_ATTR_USERSPACE
      * actions as the OVS_USERSPACE_ATTR_PID attribute's value, for use in
-     * flows whose packets arrived on port 'port_no'.
+     * flows whose packets arrived on port 'port_no'.  In the case where the
+     * provider allocates multiple Netlink PIDs to a single port, it may use
+     * 'hash' to spread load among them.  The caller need not use a particular
+     * hash function; a 5-tuple hash is suitable.
+     *
+     * (The datapath implementation might use some different hash function for
+     * distributing packets received via flow misses among PIDs.  This means
+     * that packets received via flow misses might be reordered relative to
+     * packets received via userspace actions.  This is not ordinarily a
+     * problem.)
      *
      * A 'port_no' of UINT32_MAX should be treated as a special case.  The
      * implementation should return a reserved PID, not allocated to any port,
@@ -204,7 +213,8 @@ struct dpif_class {
      *
      * A dpif provider that doesn't have meaningful Netlink PIDs can use NULL
      * for this function.  This is equivalent to always returning 0. */
-    uint32_t (*port_get_pid)(const struct dpif *dpif, odp_port_t port_no);
+    uint32_t (*port_get_pid)(const struct dpif *dpif, odp_port_t port_no,
+                             uint32_t hash);
 
     /* Attempts to begin dumping the ports in a dpif.  On success, returns 0
      * and initializes '*statep' with any data needed for iteration.  On
--- openvswitch-2.11.2.orig/lib/dpif.c
+++ openvswitch-2.11.2/lib/dpif.c
@@ -733,7 +733,16 @@ dpif_port_query_by_name(const struct dpi
 
 /* Returns the Netlink PID value to supply in OVS_ACTION_ATTR_USERSPACE
  * actions as the OVS_USERSPACE_ATTR_PID attribute's value, for use in
- * flows whose packets arrived on port 'port_no'.
+ * flows whose packets arrived on port 'port_no'.  In the case where the
+ * provider allocates multiple Netlink PIDs to a single port, it may use
+ * 'hash' to spread load among them.  The caller need not use a particular
+ * hash function; a 5-tuple hash is suitable.
+ *
+ * (The datapath implementation might use some different hash function for
+ * distributing packets received via flow misses among PIDs.  This means
+ * that packets received via flow misses might be reordered relative to
+ * packets received via userspace actions.  This is not ordinarily a
+ * problem.)
  *
  * A 'port_no' of ODPP_NONE is a special case: it returns a reserved PID, not
  * allocated to any port, that the client may use for special purposes.
@@ -744,10 +753,10 @@ dpif_port_query_by_name(const struct dpi
  * update all of the flows that it installed that contain
  * OVS_ACTION_ATTR_USERSPACE actions. */
 uint32_t
-dpif_port_get_pid(const struct dpif *dpif, odp_port_t port_no)
+dpif_port_get_pid(const struct dpif *dpif, odp_port_t port_no, uint32_t hash)
 {
     return (dpif->dpif_class->port_get_pid
-            ? (dpif->dpif_class->port_get_pid)(dpif, port_no)
+            ? (dpif->dpif_class->port_get_pid)(dpif, port_no, hash)
             : 0);
 }
 
--- openvswitch-2.11.2.orig/lib/dpif.h
+++ openvswitch-2.11.2/lib/dpif.h
@@ -274,6 +274,18 @@
  *
  *    - Upcalls that specify the "special" Netlink PID are queued separately.
  *
+ * Multiple threads may want to read upcalls simultaneously from a single
+ * datapath.  To support multiple threads well, one extends the above preferred
+ * behavior:
+ *
+ *    - Each port has multiple PIDs.  The datapath distributes "miss" upcalls
+ *      across the PIDs, ensuring that a given flow is mapped in a stable way
+ *      to a single PID.
+ *
+ *    - For "action" upcalls, the thread can specify its own Netlink PID or
+ *      other threads' Netlink PID of the same port for offloading purpose
+ *      (e.g. in a "round robin" manner).
+ *
  *
  * Packet Format
  * =============
@@ -458,7 +470,8 @@ int dpif_port_query_by_name(const struct
                             struct dpif_port *);
 int dpif_port_get_name(struct dpif *, odp_port_t port_no,
                        char *name, size_t name_size);
-uint32_t dpif_port_get_pid(const struct dpif *, odp_port_t port_no);
+uint32_t dpif_port_get_pid(const struct dpif *, odp_port_t port_no,
+                           uint32_t hash);
 
 struct dpif_port_dump {
     const struct dpif *dpif;
--- openvswitch-2.11.2.orig/ofproto/ofproto-dpif-upcall.c
+++ openvswitch-2.11.2/ofproto/ofproto-dpif-upcall.c
@@ -1057,6 +1057,7 @@ classify_upcall(enum dpif_upcall_type ty
  * initialized with at least 128 bytes of space. */
 static void
 compose_slow_path(struct udpif *udpif, struct xlate_out *xout,
+                  const struct flow *flow,
                   odp_port_t odp_in_port, ofp_port_t ofp_in_port,
                   struct ofpbuf *buf, uint32_t meter_id,
                   struct uuid *ofproto_uuid)
@@ -1074,7 +1075,7 @@ compose_slow_path(struct udpif *udpif, s
     port = xout->slow & (SLOW_CFM | SLOW_BFD | SLOW_LACP | SLOW_STP)
         ? ODPP_NONE
         : odp_in_port;
-    pid = dpif_port_get_pid(udpif->dpif, port);
+    pid = dpif_port_get_pid(udpif->dpif, port, flow_hash_5tuple(flow, 0));
 
     size_t offset;
     size_t ac_offset;
@@ -1232,7 +1233,7 @@ upcall_xlate(struct udpif *udpif, struct
                          odp_actions->data, odp_actions->size);
     } else {
         /* upcall->put_actions already initialized by upcall_receive(). */
-        compose_slow_path(udpif, &upcall->xout,
+        compose_slow_path(udpif, &upcall->xout, upcall->flow,
                           upcall->flow->in_port.odp_port, upcall->ofp_in_port,
                           &upcall->put_actions,
                           upcall->ofproto->up.slowpath_meter_id,
@@ -2195,7 +2196,7 @@ revalidate_ukey__(struct udpif *udpif, c
             goto exit;
         }
 
-        compose_slow_path(udpif, xoutp, ctx.flow.in_port.odp_port,
+        compose_slow_path(udpif, xoutp, &ctx.flow, ctx.flow.in_port.odp_port,
                           ofp_in_port, odp_actions,
                           ofproto->up.slowpath_meter_id, &ofproto->uuid);
     }
--- openvswitch-2.11.2.orig/ofproto/ofproto-dpif-xlate.c
+++ openvswitch-2.11.2/ofproto/ofproto-dpif-xlate.c
@@ -3157,7 +3157,8 @@ compose_sample_action(struct xlate_ctx *
 
     odp_port_t odp_port = ofp_port_to_odp_port(
         ctx->xbridge, ctx->xin->flow.in_port.ofp_port);
-    uint32_t pid = dpif_port_get_pid(ctx->xbridge->dpif, odp_port);
+    uint32_t pid = dpif_port_get_pid(ctx->xbridge->dpif, odp_port,
+                                     flow_hash_5tuple(&ctx->xin->flow, 0));
     size_t cookie_offset = odp_put_userspace_action(pid, cookie,
                                                     sizeof *cookie,
                                                     tunnel_out_port,
@@ -4707,7 +4708,8 @@ put_controller_user_action(struct xlate_
 
     odp_port_t odp_port = ofp_port_to_odp_port(ctx->xbridge,
                                              ctx->xin->flow.in_port.ofp_port);
-    uint32_t pid = dpif_port_get_pid(ctx->xbridge->dpif, odp_port);
+    uint32_t pid = dpif_port_get_pid(ctx->xbridge->dpif, odp_port,
+                                     flow_hash_5tuple(&ctx->xin->flow, 0));
     odp_put_userspace_action(pid, &cookie, sizeof cookie, ODPP_NONE,
                              false, ctx->odp_actions);
 }
